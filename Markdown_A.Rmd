---
title: "Homework 01 Part A"
author: "Verdini - Romeo"
date: "14/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Randomize this...

### 1.1 Pick a specific (small) graph G (even a random graph) and get its true opt(G) or, at the very least, a quite good approximation to opt(G).

```{r include=TRUE, message=FALSE}
# Used libraries
library(igraph)
library(sdpt3r)
library(glue)
library(mc2d)
library(ggplot2)
library(knitr)
library(emo)

```

In order to accomplish this first part of the HW, it has been decided to use two graphs: a small one generated by the Erdős–Rényi random graph algorithm (implemented inside igraph library) and a second \textbb{very} small one (which is the one reported in the first .pdf file).
Below is reported the code used to return the before mentioned graphs:

```{r include=FALSE}
set.seed(161821)#1618216
```

```{r include=TRUE}
ER_graph = erdos.renyi.game(10,p=1/3, type = 'gnp', directed=FALSE) # Erdős–Rényi
VS_graph = graph_from_literal(1--2, 1--4, 2--3, 4--3, 3--5, 5--6, 5--7) # the very small one
```

In the figure below the nodes colored in green represent a possible maxcut. Actually, in the "very small graph" also the purple nodes represent a maxcut, and this is a coincidence `r emo::ji("smile")` . 

```{r, figures-side, fig.show="hold", out.width="50%"}

# plot graphs highlighting nodes representing the maxcut
include_nodes <- c(2,3,5) # nodes for the mask in the vertex.color variable
plot(VS_graph, vertex.size=25, vertex.frame.color="black",
     vertex.label.color="black",
     vertex.color=c("purple",'green')[1+(V(VS_graph)%in%include_nodes)],
     vertex.label.cex=1.5, vertex.label.dist=0, edge.curved=0, edge.color=('black'),
     xlim=c(-1,1), ylim=c(-1,1))
title("'Very' small one", adj = 0, line = -5)

list_nodes <- c(3,4,5,10) # nodes for the mask in the vertex.color variable
plot(ER_graph, vertex.color=c("purple",'green')[1+(V(VS_graph)%in%list_nodes)],
     vertex.size=30, vertex.frame.color="black", vertex.label.color="black",
     vertex.label.cex=1, vertex.label.dist=0,
     edge.curved=0, edge.color='black',
     xlim=c(-1,1), ylim=c(-1,1))
title("Erdős–Rényi", adj = 0, line = -5)
```


The computation of the OPT(g) has been performed by using the maxcut() function, available in the sdpt3r library. However this one returns only an approximation of the actual value. The library returns the minimum of a related convex optimization problem, explaining why the returned value is negative. 

Below is reported the code used to compute the OPTs(g). For the VS_graph the returned value is very close to the real one, in this case 7. 

```{r include=TRUE}
ER_matrix = as.matrix(as_adj(ER_graph)) # covert graph into matrix
VS_matrix = as.matrix(as_adj(VS_graph)) # convert graph into matrix


print(glue('ER maxcut: {round(maxcut(ER_matrix)$pobj,2)} & VS maxcut: {round(maxcut(VS_matrix)$pobj,2)}'))
```

### 1.2 Run the Randomized Max-Cut Algorithm a large number M of times & Evaluate the average cut-size over these M simulations and compare it with the theoretical bound opt(G)/2.

It has been proved that $E(card(\delta(U)) >= \frac{OPT}{2}$. In order to compute the EXP for both graphs, the maxcut algorithm has been executed 100000 number of times. Below is reported the code used to check the inequality.

From now on, OPT_sdpt3r will represent the approximated OPT value from the maxcut() algorithm, whereas the OPT_E will represent the one returned by the Paul Erdos algorithm.


```{r include=TRUE}

for (m in 1:2){
  
  g_matrices <-list(ER_matrix, VS_matrix)
  name_graphs <- c('ER_graph', 'VS_graph')
  OPT_names <- c('OPT_sdpt3r', 'OPT_E')
  g_dimension = dim(g_matrices[[m]])[1]
  
  sum = 0
  for (n in 1:100000){
    mask = rbern(n = g_dimension, prob=.5) 
    vector = c(1:g_dimension)
    indeces_U = vector[!!mask] # this is a little workaround to have a mask with TRUE and FALSE instead of 1 0
    indeces_not_U = vector[!mask] 
    num_edges = sum(g_matrices[[m]][indeces_U, indeces_not_U]) 
    sum = sum+num_edges
  }
  exp = sum/100000
  print(glue('{name_graphs[m]}: EXP= {exp} & {OPT_names[m]}/2= {round(-maxcut(g_matrices[[m]])$pobj/2,2)}'))
}
```

### 1.3 Finally change the graph size to see if there is an impact on the performance.

Here the two algorithms have been tested on graphs with different sizes spanning from 10 to 200 verteces. The graphs have been generated by using the "erdos.renyi.game" model with probability p=1/3.   


```{r include=TRUE, eval = FALSE}
Paul_Erdos_function = function(gen_graph){
  
  starting = proc.time()
  g_matrix = as.matrix(as_adj(gen_graph))
  g_dimension = dim(g_matrix)
  
  sum = 0
  for (n in 1:100000){
    mask = rbern(n = g_dimension, prob=.5) 
    vector = c(1:g_dimension)
    indeces_U = vector[!!mask] # this is a little workaround to have a mask with TRUE and FALSE instead of 1 0
    indeces_not_U = vector[!mask] 
    num_edges = sum(g_matrix[indeces_U, indeces_not_U]) 
    sum = sum+num_edges
  }
  exp = sum/100000
  end_time = proc.time() - starting 
  return(end_time[[3]])
}

maxcut_function = function(gen_graph){

  starting = proc.time()
  
  g_matrix = as.matrix(as_adj(gen_graph))
  maxcut_value = maxcut(g_matrix)$pobj

  end_time = proc.time() - starting 
  return(end_time[[3]])
}
```

```{r include=TRUE, eval = FALSE}
# compute elapsed time for Paul Erdos

time_elapsed_PE <- c()

for (n in seq(from = 10, to = 200, by = 10)) {
  intermediated_time = 0
  for (l in 1:5){
    intermediated_time = intermediated_time +  
      Paul_Erdos_function(erdos.renyi.game(n,p=1/3, type = 'gnp', directed=FALSE))
  }
  time_elapsed_PE <- c(time_elapsed_PE, round(intermediated_time/5,3))
}
```

```{r include=TRUE, eval = FALSE}
#Compute elapsed time for the maxcut algorithm implemented in the sdpt3r library

time_elapsed_maxcut <- c()
for (n in seq(from = 10, to = 200, by = 10)) {
  intermediated_time = 0
  for (l in 1:5){
    intermediated_time = intermediated_time +  
      maxcut_function(erdos.renyi.game(n,p=1/3, type = 'gnp', directed=FALSE))
  }
  time_elapsed_maxcut <- c(time_elapsed_maxcut, round(intermediated_time/5,3))
}
```

```{r include=TRUE, eval = FALSE}
# store results into dataframe
PE_performances <- data.frame('n_of_nodes' = seq(from = 10, to = 200, by = 10),
                              'elapsed_time_PE' = time_elapsed_PE,
                              'elapsed_time_maxcut' = time_elapsed_maxcut)
```

```{r include=TRUE, eval=FALSE}
write.csv(PE_performances,"performances.csv", row.names = FALSE)
```

```{r include=FALSE, eval=TRUE}
PE_performances <- read.csv("performances.csv")
```


```{r echo = FALSE, results = 'asis', include=TRUE}
# plot table with performances results:

kable(PE_performances, caption= "Time colplexity Table")
```

If the graph size increases, it is possible to see how the maxcut() algorithm, implemented in the sdpt3r library, becomes very computationally expensive in terms of time. On the other hand, the Paul Erdos maxcut algorithm seems very effective in terms of performances. The increasing complexity, in terms of time, is represented below by using a line plot:

```{r include=TRUE}
# plot the two curves representing different performances in terms of time:


ggplot(PE_performances, aes(x=n_of_nodes))+
  
  geom_line(aes(y=elapsed_time_PE, color="#09611D"), size=1) +
  geom_point(aes(y=elapsed_time_PE), shape=21, color="#09611D", fill="#F34835", size=3) + 
  
  geom_line(aes(y=elapsed_time_maxcut, color="#F3C035"), size=1) + 
  geom_point(aes(y=elapsed_time_maxcut), color="#F3C035", shape=21, fill="purple", size=3) +
  
  labs(title = "Time Complexity Plot" , x = 'number of nodes', y= 'elapsed time [s]') +
  scale_color_identity(name = "Algorithms",
                       breaks = c("#09611D", "#F3C035"),
                       labels = c("Paul Erdos", "Maxcut"),
                       guide = "legend") +
  coord_cartesian(xlim = c(0,201), ylim = c(0,20))
```

